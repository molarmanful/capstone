  This week's experiments were not necessarily related to how I want the final visual design of my capstone to look like. Rather, I am using these experiments to test the limits of TouchDesigner's realtime rendering capabilities. This is especially important as it gives me an idea of how complex I can/should make the visual component (e.g. how many objects I can have in one scene).

<blockquote class="imgur-embed-pub" lang="en" data-id="a/qWFmW3G"  ><a href="//imgur.com/a/qWFmW3G">TD Render Stress Tests</a></blockquote><script async src="//s.imgur.com/min/embed.js" charset="utf-8"></script>

<blockquote class="imgur-embed-pub" lang="en" data-id="a/POvgljg"  ><a href="//imgur.com/a/POvgljg">TD Render Stress Tests (Nodes)</a></blockquote><script async src="//s.imgur.com/min/embed.js" charset="utf-8"></script>

What was tested:

- Substance Designer integration and PBR materials, vertex displacement, HDRI lighting and skybox display.
- Sampling video frames to create dynamic texture-based instancing, audio syncing with visuals.
- Image manipulation effects (i.e. blurs) to affect displacement of objects separately from texture, visual displaying of point lights, tilt-shift-style depth-of-field compositing.